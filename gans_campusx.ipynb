{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35cd442f-a2d2-4c24-a4c7-8067e9eb7387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.1.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.10.26)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.50.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.28.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177346b0-7f94-49a2-b0f4-b511753dc688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 21:37:16.600967: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 21:37:16.778000: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-22 21:37:16.778035: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-22 21:37:17.589361: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-22 21:37:17.589472: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-22 21:37:17.589485: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#get dataset\n",
    "from keras.datasets.cifar10 import load_data\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#load dataset\n",
    "(trainX,trainy),(testX,testy) = load_data() #total 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa9d658-6ed1-46fb-a957-be88c0d9c596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show images\n",
    "fig,axes=plt.subplots(1,6,figsize=(8,2))\n",
    "plt.title('Real data',fontdict={'horizontalalignment': 'center'},loc='center')\n",
    "#fig.suptitle('Real data')\n",
    "for ax in axes.flatten():\n",
    "    idx=np.random.randint(len(trainX))\n",
    "    ax.set_axis_off()\n",
    "    #ax.imshow(trainX[idx])\n",
    "    \n",
    "fig.savefig('gan_plots/fig.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ca6f2a-f6e9-4ebb-84f7-e432b64ad915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Reshape\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16dc28e4-3d3b-4265-a816-f5c474e4696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining discriminator model\n",
    "def define_descriminator(in_shape=(32,32,3)):\n",
    "    model=Sequential()\n",
    "    #normal\n",
    "    model.add(Conv2D(64,(3,3),padding='same',input_shape=in_shape))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #downsampling\n",
    "    model.add(Conv2D(128,(3,3),strides=(2,2),padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #downsampling\n",
    "    model.add(Conv2D(128,(3,3),strides=(2,2),padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #downsampling\n",
    "    model.add(Conv2D(256,(3,3),strides=(2,2),padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #classifier\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "              \n",
    "    #compile model\n",
    "    model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.0002,beta_1=0.5), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df9732a5-3e19-44b2-bc9a-5351d7d4682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 522,497\n",
      "Trainable params: 522,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 21:37:19.803126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-22 21:37:19.803186: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-22 21:37:19.803215: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ae61cf1764fd): /proc/driver/nvidia/version does not exist\n",
      "2022-11-22 21:37:19.803610: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "model=define_descriminator()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f14f3c21-9f79-42ac-b2d4-6a29bfbb6b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and scale real data\n",
    "def load_real_samples():\n",
    "    (trainX,_),(_,_)=load_data()\n",
    "    X=trainX.astype('float32')\n",
    "    #scale from (0,255) to (-1,1) for better performance in gans\n",
    "    X=(X-127.5)/127.5\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a63827a-f526-4198-8dc0-003492a2425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select real samples\n",
    "def generate_real_samples(dataset,n_samples):\n",
    "    #choose random samples\n",
    "    ix=np.random.randint(0,len(dataset),n_samples)\n",
    "    X=dataset[ix]\n",
    "    #generate real class label i.e 1\n",
    "    y=np.ones((n_samples,1))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1e5d472-8898-4351-a69b-85bcb31746be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate fake samples with label\n",
    "def generate_fake_samples(n_samples):\n",
    "    #generate uniform random numbers in range (0,1)\n",
    "    X=np.random.rand(32*32*3*n_samples)\n",
    "    X= -1 + X*2\n",
    "    X=X.reshape((n_samples,32,32,3))\n",
    "    #generate fake class labels i.e 0\n",
    "    y=np.zeros((n_samples,1))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afbf2a69-6d01-4b80-9541-f9fa7080aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train discriminator model temporarily\n",
    "def train_discriminator(model,dataset,n_iter=20,n_batch=128):\n",
    "    half_batch=int(n_batch/2)\n",
    "    \n",
    "    #loop for no. of epochs (n_iters)\n",
    "    for i in range(n_iter):\n",
    "        #train on real samples\n",
    "        X_real,y_real=generate_real_samples(dataset,half_batch)\n",
    "        _,real_accuracy=model.train_on_batch(X_real,y_real)\n",
    "        #train on fake samples\n",
    "        X_fake,y_fake=generate_fake_samples(half_batch)\n",
    "        _,fake_accuracy=model.train_on_batch(X_fake,y_fake)    \n",
    "        \n",
    "        print(f'Epoch:{i} Accuracy : real data = {real_accuracy*100}% , fake data = {fake_accuracy*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77896771-3362-4c55-a747-2037886ad861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Accuracy : real data = 35.9375% , fake data = 3.125%\n",
      "Epoch:1 Accuracy : real data = 90.625% , fake data = 10.9375%\n",
      "Epoch:2 Accuracy : real data = 92.1875% , fake data = 39.0625%\n",
      "Epoch:3 Accuracy : real data = 95.3125% , fake data = 73.4375%\n",
      "Epoch:4 Accuracy : real data = 90.625% , fake data = 100.0%\n",
      "Epoch:5 Accuracy : real data = 90.625% , fake data = 100.0%\n",
      "Epoch:6 Accuracy : real data = 75.0% , fake data = 100.0%\n",
      "Epoch:7 Accuracy : real data = 95.3125% , fake data = 100.0%\n",
      "Epoch:8 Accuracy : real data = 84.375% , fake data = 100.0%\n",
      "Epoch:9 Accuracy : real data = 79.6875% , fake data = 100.0%\n",
      "Epoch:10 Accuracy : real data = 93.75% , fake data = 100.0%\n",
      "Epoch:11 Accuracy : real data = 96.875% , fake data = 100.0%\n",
      "Epoch:12 Accuracy : real data = 98.4375% , fake data = 100.0%\n",
      "Epoch:13 Accuracy : real data = 98.4375% , fake data = 100.0%\n",
      "Epoch:14 Accuracy : real data = 98.4375% , fake data = 100.0%\n",
      "Epoch:15 Accuracy : real data = 96.875% , fake data = 100.0%\n",
      "Epoch:16 Accuracy : real data = 100.0% , fake data = 100.0%\n",
      "Epoch:17 Accuracy : real data = 100.0% , fake data = 100.0%\n",
      "Epoch:18 Accuracy : real data = 100.0% , fake data = 100.0%\n",
      "Epoch:19 Accuracy : real data = 100.0% , fake data = 100.0%\n"
     ]
    }
   ],
   "source": [
    "#example training discriminator modek\n",
    "model=define_descriminator()\n",
    "dataset=load_real_samples()\n",
    "train_discriminator(model,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b576a3ed-252f-4618-bb2b-f6964022930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define generator model\n",
    "def define_generator(latent_dim):\n",
    "    model=Sequential()\n",
    "    #foundation for 4*4 image\n",
    "    n_nodes=256*4*4\n",
    "    model.add(Dense(n_nodes,input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((4,4,256)))\n",
    "    #upscale to 8*8\n",
    "    model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #upscale to 16*16\n",
    "    model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #upscale to 32*32\n",
    "    model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #output layer\n",
    "    model.add(Conv2D(3,(3,3),activation='tanh',padding='same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94d0ddba-7909-476f-a2e9-530073fb3c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 4096)              413696    \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 4096)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 128)        524416    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 128)      262272    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 128)      262272    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 32, 32, 3)         3459      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,466,115\n",
      "Trainable params: 1,466,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define latent space\n",
    "latent_dim=100\n",
    "#define generator model\n",
    "model=define_generator(latent_dim)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d6e7eb5-46db-4d2e-aef1-ccc1209b20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate points in latent space as input to generator\n",
    "def generate_latent_points(latent_dim,n_samples):\n",
    "    X_input=np.random.randn(latent_dim*n_samples)\n",
    "    X_input=X_input.reshape(n_samples,latent_dim)\n",
    "    return X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db22e53-e780-4908-b4df-f28cad403d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use generator to generate fake examples with class label\n",
    "def generate_fake_samples(g_model,latent_dim,n_samples):\n",
    "    #generate points in latent space\n",
    "    X_input=generate_latent_points(latent_dim,n_samples)\n",
    "    #predict outputs\n",
    "    X=g_model.predict(X_input)\n",
    "    #create fale class labels i.e 0\n",
    "    y=np.zeros((n_samples,1))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db7ebb43-d2f6-4dbc-b116-f16b9a48b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define gan i.e combined discriminator and generator\n",
    "def gan(g_model,d_model):\n",
    "    #freeze discriminator model weights\n",
    "    d_model.trainable=False\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=0.0002,beta_1=0.5))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7691033b-7a35-4c48-9bda-16d09c9d8a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_4 (Sequential)   (None, 32, 32, 3)         1466115   \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 1)                 522497    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,988,612\n",
      "Trainable params: 1,466,115\n",
      "Non-trainable params: 522,497\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#size of latent dim\n",
    "latent_dim=100\n",
    "#generate gan model\n",
    "d_model=define_descriminator()\n",
    "g_model=define_generator(latent_dim)\n",
    "gan_model=gan(g_model,d_model)\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca574e60-3fea-4179-af47-9a2ee0c2b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train generator and discriminator\n",
    "def train(g_model,d_model,gan_model,dataset,latent_dim,n_epochs=200,n_batch=128):\n",
    "    batch_per_epoch=int(len(dataset)/n_batch)\n",
    "    half_batch=int(n_batch/2)\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(batch_per_epoch):\n",
    "            #train discriminator on real samples\n",
    "            X_real,y_real=generate_real_samples(dataset,half_batch)\n",
    "            d_loss1,_=d_model.train_on_batch(X_real,y_real)\n",
    "            #train discriminator on fake samples\n",
    "            X_fake,y_fake=generate_fake_samples(g_model,latent_dim,half_batch)\n",
    "            d_loss2,_=d_model.train_on_batch(X_fake,y_fake)\n",
    "            #generate latent dims for generator\n",
    "            X_gan=generate_latent_points(latent_dim,n_batch)\n",
    "            #create inverted labels for fake samples\n",
    "            y_gan=np.ones((n_batch,1))\n",
    "            #update generator via discriminators error\n",
    "            g_loss=gan_model.train_on_batch(X_gan,y_gan)\n",
    "            \n",
    "            #summarize data            \n",
    "            if (j+1)%30==0:\n",
    "                print(f'epoch:{i}/{n_epochs} ,batch:{j}/{batch_per_epoch} ,disc_loss(real):{d_loss1} ,disc_loss(fake):{d_loss2} ,gan_loss:{g_loss}')\n",
    "            \n",
    "        if (i+1)%10==0:\n",
    "            #evaluate discriminator\n",
    "            summarize_performance(i+1,g_model,d_model,dataset,latent_dim)\n",
    "        \n",
    "        #summarize data\n",
    "        #print(f'epoch:{i}/{n_epochs} ,disc_loss(real):{d_loss1} ,disc_loss(fake):{d_loss2} ,gan_loss:{g_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c82fde2-2f6e-45c2-bf35-5f212bbad399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate discriminator\n",
    "def summarize_performance(epoch,g_model,d_model,dataset,latent_dim,n_samples=150):\n",
    "    X_real,y_real=generate_real_samples(dataset,half_batch)\n",
    "    _,acc_real=d_model.evaluate(X_real,y_real)\n",
    "    #train discriminator on fake samples\n",
    "    X_fake,y_fake=generate_fake_samples(g_model,latent_dim,half_batch)\n",
    "    _,acc_fake=d_model.evaluate(X_fake,y_fake)\n",
    "    \n",
    "    print(f'Accuracy: real_data:{acc_real*100} ,fake_data:{acc_fake*100}')\n",
    "    save_plot(X_fake,epoch)\n",
    "    g_model.save('generator_model.h5',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43838011-5f3e-48cf-88c0-3a686c8c4cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plt(examples,epoch,n=6):\n",
    "    #scale from (-1,1) to (0,1)\n",
    "    examples=(examples+1)/2.0\n",
    "    #show images\n",
    "    fig,axes=plt.subplots(1,n,figsize=(8,2))\n",
    "    plt.title(f'generated_img (epoch={epoch})',fontdict={'horizontalalignment': 'center'},loc='center')\n",
    "    #fig.suptitle('Real data')\n",
    "    for ax in axes.flatten():\n",
    "        idx=np.random.randint(len(examples))\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow(examples[idx])\n",
    "        \n",
    "    fig.savefig(f'gan_plots/generated_img_epoch{epoch}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d051a28-e916-478f-a867-ccb65cbfa7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_real_samples()\n",
    "train(g_model,d_model,gan_model,dataset,latent_dim,n_epochs=200,n_batch=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe697968-82f4-4add-a9d1-eb5200d3b4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_model.save('generator_model.h5',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f06160f-10cb-4d51-92f6-7ec56dba3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "#Generate new images\n",
    "model=load_model('generator_model.h5')\n",
    "latent_points=generate_latent_points(100,100)\n",
    "X=model.predict(latent_points)\n",
    "#Scale from (-1,1) to (0,1)\n",
    "X=(X+1)/2\n",
    "\n",
    "fig,axes=plt.subplots(1,n,figsize=(8,2))\n",
    "fig.suptitle('Real data')\n",
    "for ax in axes.flatten():\n",
    "    idx=np.random.randint(len(X))\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9114c78-a5a7-4771-84c6-e6144592d019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
